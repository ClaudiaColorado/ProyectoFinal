name: Dynamic Databricks Proyecto Final Deploy v3
on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install jq & curl
        run: sudo apt-get update && sudo apt-get install -y jq curl

      - name: Export multiple notebooks (raw)
        run: |
          ORIGIN_HOST=${{ secrets.DATABRICKS_ORIGIN_HOST }}
          ORIGIN_TOKEN=${{ secrets.DATABRICKS_ORIGIN_TOKEN }}
          NOTEBOOK_BASE="/workspace/Users/claudiacoloradofc@gmail.com/ProyectoFinal/1_Proceso"
          NOTEBOOKS=("drop_medallion" "00_prep_env" "01_ingest" "02_transform" "03_load")
          mkdir -p notebooks_to_deploy
          for nb in "${NOTEBOOKS[@]}"; do
            echo "Exportando $nb en modo raw..."
            curl -s -X GET \
              -H "Authorization: Bearer $ORIGIN_TOKEN" \
              "$ORIGIN_HOST/api/2.0/workspace/export?path=$NOTEBOOK_BASE/$nb&format=SOURCE&direct_download=true" \
              --output "notebooks_to_deploy/$nb.py"
          done

      - name: Set destination base once
        run: |
          echo 'DEST_NOTEBOOK_BASE=/Workspace/Users/claudiacoloradofc@gmail.com/ProyectoFinal/1_Proceso' >> $GITHUB_ENV

      - name: Deploy notebooks to Destination Workspace
        run: |
          DEST_HOST=${{ secrets.DATABRICKS_DEST_HOST }}
          DEST_TOKEN=${{ secrets.DATABRICKS_DEST_TOKEN }}
          DEST_BASE="${{ env.DEST_NOTEBOOK_BASE }}"
          for file in notebooks_to_deploy/*.py; do
            name=$(basename "$file" .py)
            dest_path="$DEST_BASE/$name"
            echo "Creando carpeta $DEST_BASE si no existe..."
            curl -s -X POST \
              -H "Authorization: Bearer $DEST_TOKEN" \
              -H "Content-Type: application/json" \
              -d "{\"path\":\"$DEST_BASE\"}" \
              "$DEST_HOST/api/2.0/workspace/mkdirs"
            echo "Importando $file ‚Üí $dest_path"
            response=$(curl -s -X POST \
              -H "Authorization: Bearer $DEST_TOKEN" \
              -H "Content-Type: multipart/form-data" \
              -F "path=$dest_path" \
              -F "format=SOURCE" \
              -F "language=PYTHON" \
              -F "overwrite=true" \
              -F "content=@$file" \
              "$DEST_HOST/api/2.0/workspace/import")
            echo "Response: $response"
          done

      - name: Verify notebooks exist in destination
        run: |
          set -euo pipefail
          DEST_HOST=${{ secrets.DATABRICKS_DEST_HOST }}
          DEST_TOKEN=${{ secrets.DATABRICKS_DEST_TOKEN }}
          DEST_BASE="${{ env.DEST_NOTEBOOK_BASE }}"
          echo "üîé Verificando notebooks en $DEST_BASE ..."
          for nb in drop_medallion 00_prep_env 01_ingest 02_transform 03_load; do
            path="$DEST_BASE/$nb"
            echo "  ‚Üí $path"
            resp=$(curl -s -H "Authorization: Bearer $DEST_TOKEN" \
                        "$DEST_HOST/api/2.0/workspace/get-status?path=$path")
            echo "$resp" | jq .
            type=$(echo "$resp" | jq -r '.object_type // empty')
            if [[ "$type" != "NOTEBOOK" ]]; then
              echo "‚ùå No se encontr√≥ como NOTEBOOK: $path"
              exit 1
            fi
          done
          echo "‚úÖ Todos los notebooks existen en destino."

      - name: Check if workflow exists and delete if necessary
        run: |
          DEST_HOST=${{ secrets.DATABRICKS_DEST_HOST }}
          DEST_TOKEN=${{ secrets.DATABRICKS_DEST_TOKEN }}
          WORKFLOW_NAME="WF_ADB"
          echo "Verificando si existe el workflow: $WORKFLOW_NAME"
          workflows_response=$(curl -s -X GET \
            -H "Authorization: Bearer $DEST_TOKEN" \
            "$DEST_HOST/api/2.1/jobs/list")
          existing_job_id=$(echo "$workflows_response" | jq -r --arg name "$WORKFLOW_NAME" '.jobs[]? | select(.settings.name == $name) | .job_id')
          if [ "$existing_job_id" != "" ] && [ "$existing_job_id" != "null" ]; then
            echo "Workflow encontrado con ID: $existing_job_id. Eliminando..."
            delete_response=$(curl -s -X POST \
              -H "Authorization: Bearer $DEST_TOKEN" \
              -H "Content-Type: application/json" \
              -d "{\"job_id\": $existing_job_id}" \
              "$DEST_HOST/api/2.1/jobs/delete")
            echo "Delete response: $delete_response"
          else
            echo "No se encontr√≥ workflow existente con nombre: $WORKFLOW_NAME"
          fi

      - name: Get existing cluster ID
        run: |
          DEST_HOST=${{ secrets.DATABRICKS_DEST_HOST }}
          DEST_TOKEN=${{ secrets.DATABRICKS_DEST_TOKEN }}
          CLUSTER_NAME="cluster_SD"
          echo "Buscando cluster existente: $CLUSTER_NAME"
          clusters_response=$(curl -s -X GET \
            -H "Authorization: Bearer $DEST_TOKEN" \
            "$DEST_HOST/api/2.0/clusters/list")
          echo "Clusters response: $clusters_response"
          cluster_id=$(echo "$clusters_response" | jq -r --arg name "$CLUSTER_NAME" '.clusters[]? | select(.cluster_name == $name) | .cluster_id')
          if [ "$cluster_id" != "" ] && [ "$cluster_id" != "null" ]; then
            echo "‚úÖ Cluster encontrado: $CLUSTER_NAME con ID: $cluster_id"
            echo "CLUSTER_ID=$cluster_id" >> $GITHUB_ENV
          else
            echo "‚ùå No se encontr√≥ el cluster: $CLUSTER_NAME"
            echo "Clusters disponibles:"
            echo "$clusters_response" | jq -r '.clusters[]? | .cluster_name'
            exit 1
          fi

      - name: Create/Update Databricks Workflow WF_ProyectoFinal (idempotente)
        shell: bash
        env:
          DEST_HOST: ${{ secrets.DATABRICKS_DEST_HOST }}
          DEST_TOKEN: ${{ secrets.DATABRICKS_DEST_TOKEN }}
          DEST_BASE: ${{ env.DEST_NOTEBOOK_BASE }}
          CLUSTER_ID: ${{ env.CLUSTER_ID }}
        run: |
          set -euo pipefail
          echo "Creando/actualizando workflow: WF_ProyectoFinal con cluster ID: ${CLUSTER_ID}"
          echo "DEST_BASE = ${DEST_BASE}"
          # 1) Construir settings.json (config del job)
          jq -n \
            --arg base "$DEST_BASE" \
            --arg cid  "$CLUSTER_ID" \
            '{
              name: "WF_ProyectoFinal",
              max_concurrent_runs: 1,
              tasks: [
                {
                  task_key: "drop_medallion",
                  source: "WORKSPACE",
                  notebook_task: { notebook_path: ($base + "/drop_medallion") },
                  existing_cluster_id: $cid,
                  timeout_seconds: 3600
                },
                {
                  task_key: "00_prep_env",
                  depends_on: [ { task_key: "drop_medallion" } ],
                  source: "WORKSPACE",
                  notebook_task: { notebook_path: ($base + "/00_prep_env") },
                  existing_cluster_id: $cid,
                  timeout_seconds: 3600
                },
                {
                  task_key: "01_ingest",
                  depends_on: [ { task_key: "00_prep_env" } ],
                  source: "WORKSPACE",
                  notebook_task: { notebook_path: ($base + "/01_ingest") },
                  existing_cluster_id: $cid,
                  timeout_seconds: 3600
                },
                {
                  task_key: "02_transform",
                  depends_on: [ { task_key: "01_ingest" } ],
                  source: "WORKSPACE",
                  notebook_task: { notebook_path: ($base + "/02_transform") },
                  existing_cluster_id: $cid,
                  timeout_seconds: 3600
                },
                {
                  task_key: "03_load",
                  depends_on: [ { task_key: "02_transform" } ],
                  source: "WORKSPACE",
                  notebook_task: { notebook_path: ($base + "/03_load") },
                  existing_cluster_id: $cid,
                  timeout_seconds: 3600
                }
              ]
            }' > settings.json

          echo "Settings a aplicar:"
          jq . settings.json

          # 2) Buscar si ya existe un job con ese nombre
          job_id=$(
            curl -sS -H "Authorization: Bearer ${DEST_TOKEN}" \
              "${DEST_HOST}/api/2.1/jobs/list" \
            | jq -r '.jobs[]? | select(.settings.name=="WF_ProyectoFinal") | .job_id' \
            | head -n1
          )

          if [[ -n "${job_id}" && "${job_id}" != "null" ]]; then
            echo "Job existente: ${job_id} -> reset con new_settings"
            jq -n --arg job_id "${job_id}" --argjson settings "$(cat settings.json)" \
              '{ job_id: ($job_id|tonumber), new_settings: $settings }' > reset.json

            reset_resp=$(
              curl -sS -X POST \
                -H "Authorization: Bearer ${DEST_TOKEN}" \
                -H "Content-Type: application/json" \
                --data-binary @reset.json \
                "${DEST_HOST}/api/2.1/jobs/reset"
            )
            echo "Reset response:"
            echo "${reset_resp}" | jq .

            # Validar que no haya error
            if echo "${reset_resp}" | jq -e '.error_code' >/dev/null 2>&1; then
              echo "‚ùå Error al resetear el job"
              exit 1
            fi
          else
            echo "Job no existe -> creando"
            create_resp=$(
              curl -sS -X POST \
                -H "Authorization: Bearer ${DEST_TOKEN}" \
                -H "Content-Type: application/json" \
                --data-binary @settings.json \
                "${DEST_HOST}/api/2.1/jobs/create"
            )
            echo "Create response:"
            echo "${create_resp}" | jq .

            job_id=$(echo "${create_resp}" | jq -r '.job_id')
            if [[ -z "${job_id}" || "${job_id}" == "null" ]]; then
              echo "‚ùå Error al crear el job"
              exit 1
            fi
          fi

          # 3) Verificaci√≥n: que las tasks sean notebook_task y apunten a /Workspace/...
          echo "Verificando tareas del job ${job_id}..."
          curl -sS -H "Authorization: Bearer ${DEST_TOKEN}" \
            "${DEST_HOST}/api/2.1/jobs/get?job_id=${job_id}" \
            | jq '.settings.tasks[] | {task_key, source, notebook_task,
ÓÄÄ